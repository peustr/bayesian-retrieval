{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1d0a6-f559-4bb3-997f-3c6eeb797d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from bret.data_loaders import (\n",
    "    GenericDataLoader,\n",
    "    get_text_dataloader,\n",
    "    get_training_dataloader,\n",
    ")\n",
    "from bret.models import model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61b820-a54d-4d33-84bd-d7240a194224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_key(old_key):\n",
    "    if \"embeddings\" in old_key:\n",
    "        return old_key\n",
    "    if \"norm\" in old_key.lower():\n",
    "        return old_key\n",
    "    if \"pooler\" in old_key:\n",
    "        return old_key\n",
    "    if old_key.endswith(\".weight\"):\n",
    "        return old_key.replace(\".weight\", \".weight_mean\")\n",
    "    if old_key.endswith(\".bias\"):\n",
    "        return old_key.replace(\".bias\", \".bias_mean\")\n",
    "    return old_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90666d8d-2160-42b4-8264-0957778823bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_ckpt = \"../output/trained_encoders/bert-base-dpr.pt\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "tokenizer, model = model_factory(\"bert-base\", \"bret\", device)\n",
    "sd = torch.load(encoder_ckpt, map_location=device)\n",
    "sdnew = {}\n",
    "for old_key, v in sd.items():\n",
    "    k = preprocess_key(old_key)\n",
    "    sdnew[k] = v\n",
    "model.load_state_dict(sdnew, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68d5f1-a676-4cfe-934b-765b2bcc2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dl = get_text_dataloader(\"../data/msmarco-corpus.jsonl\", batch_size=32)\n",
    "for corpus_sample in corpus_dl:\n",
    "    psg_id, psg = corpus_sample  # Get a single batch of passages from the corpus.\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273662f-395f-4438-89d6-936106281851",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    psg_enc = tokenizer(\n",
    "        psg, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    Upsg = model.compute_uncertainty(psg_enc, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92012060-4afb-4828-a658-2bf4b8d40761",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upsg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
